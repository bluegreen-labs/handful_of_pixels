---
engine: knitr
filters:
  - webr
---

# Crash course R

This chapter will briefly summarize some of the principles which will be used throughout the book. In particular, I outline some of the best practices in managing projects and the basic data manipulations using the tidy data principles. For a thourough introduction to data science in R I refer to [R for data science](https://r4ds.had.co.nz/) by Hadley & Grolemund, while open data science practices and reproducible project management I refer to [Reproducibility with R](https://eliocamp.github.io/reproducibility-with-r/) by Campitelli & Corrales. For an in depth discussion of geocomputational concepts I refer to [Geocomputation with R](https://r.geocompx.org/index.html) by Lovelace, Nowosad, Muenchow.

## Project management

From a very practical and pragmatic point of view a solid workflow requires reproducible results. The smallest unit in a reproducible workflow is the structure of your personal research project (irrespective of its contributions to a larger whole). **Structuring** a research project.

Structuring your project covers:

- the **organization of your files** (i.e. code, data, manuscripts)
- file **naming** conventions (how things are named)
- code documentation (describing what and how you do things)
- data documentation (describing data sources)
- version control (logging progress systematically)

When using R the easiest solution to many of these issues is to use an Integrated Development Environment (IDE, e.g. [RStudio](https://posit.co/downloads/) or [VS Code]()), version control to track code changes such as [git](https://git-scm.com/) and its cloud based collaborative components such as [Github](https://github.com) or [Codeberg](https://codeberg.org). The setup of both IDEs is described in @sec-setup.

It is recommended to start a new project in the RStudio IDE and provide a consistent structure grouping similar objects in folders, e.g. storing data in a `data` folder, your R scripts in the `R` folder etc. You can further select the tracking of used packages using `renv` when creating a new project.

```{r eval=FALSE}
project/
├─ your_project.Rproj
├─ vignettes/
│  ├─ your_dynamic_document.Rmd
├─ data/
│  ├─ some_data.csv
├─ R/
│  ├─ R_scripts.R
```

For those familiar with github I provide a [Github template](https://github.com/bluegreen-labs/R_project_template) which you can use when creating a new project on Github. This provides a populated project structure and removes the overhead of making decisions on how to structure a project.

::: {.callout-note}
## Note

Pay close attention to the setup of your project as an intuitive and consistent structure greatly enhances your productivity, reproducibility, replicability within a different context and the overall quality of your work. First and foremost, your project structure, the documentation you write, and the clarity of your work are notes to your future self. Be kind to your future self.
:::

## Basic R

Unlike many other frameworks for geocomputation, and in particular graphical geographic information system (GIS) such as ArcGIS and QGIS, geocomputation in R is uniquely code oriented. Some basic knowledge of data types, code structure and execution is therefore required. Within R common data structures are vectors, list objects and data frames and tibbles, which are defined as such:

```{r eval = FALSE}
# A numeric vector
v <- c(1,4,5,6)

# A named list
l <- list(
  element_a = "a",
  number_2 = 2
)

# A data frame (or structured named lists)
df <- data.frame(
  numbers = c(1,3),
  letters = c("a", "b")
)
```

Data frames in this context represent tabulated data where the content can vary.

### Subsetting and conversions

You can access data in the above data types by referring to them by index, or in some cases by name. For example,  accessing the 2th element in vector `v` can be accomplished by using `v[2]`. Element 'a' in list `l` can be accessed using 

### Basic math



### Functions

::: {.callout-tip}
## Exercise sandbox

Below you can use the in browser R session to execute some basic R commands as shown above. Execute the formatted statement by hitting `Run Code` or alter the content and re-run it.

```{webr}
# defines a function printing
# the last element of a vector
last <- function(x) {
  x[length(x)]
}

# define a demo vector
v <- c(1,3,5,7,2)

# apply the defined function
print(last(v))
```
:::

## Libraries

Not all software components are included in a basic R installation. Additional components can be installed as packages from official R archives (CRAN), or github. A full list of packages used in the rendering of the book and its examples can be found in @sec-bookinfo, where information on the automated installation of all required packages is provided in @sec-setup.

For example, we can extend the capabilities of base R by installing the `MODISTools` package from the official CRAN archive using: `install.pacakges("MODISTools")`. After a successful installation you can load packages using the `library()` function, as `library("MODISTools")`. Functions as defined within `MODISTools` can then be accessed in scripts or from the command line.

At times it can be useful to use the `::` notation in calling package functions. The `::` notation allows you to call a function without loading the full package using `library()`. For example, `MODISTools::mt_products()` calls the `mt_products()` function regardless of having loaded `MODISTools` with `library()` beforehand.

This can be done useful if you only need one particular function, and don't want to load the whole package (as this might have memory/performance implications). Furthermore, the use of `::` makes it explicit what the source package of a particular function is. This can be helpful if packages have functions with the same name, leading to confusion on the source of the function used.

For installs from external sources we need the `remotes` package. Installing a package directly from a Github location would then be possible using for example `remotes::install_github("bluegreen-labs/MODISToosl")`. Note that packages on Github or elsewhere are note reviewed, and might pose security risks to your system.

## Tidy data

Throughout the book I will structure data using a tidy data approach. Tidy data is a way of structuring data where every row represents a single sample and every row represents a single variable. The tidy data format is a **long** row orientated format. 

FIGURE

This format allows for easier grouped operations. The `dplyr` library is critical in this context as it contains most of the components to manipulate tidy data.

FIGURE

### Tidy data manipulations

Although both long or wide data formats have their advantages and drawbacks, the use of long (row oriented) data allows us to use the `dplyr` library to iterate over data quickly and transparently. Conversions to a long format from a wide (column oriented) format are therefore critical throughout this manual.

```{r eval = FALSE}
pivot_longer()
```

### Tidy data manipulations




### Tidy operations and pipes

- what is a pipe?
- what are common tidy (rowwise) operations?
  - group_by()
  - mutate()
  - summarize()

Look for figures in cheat sheets (link back to them)


::: {.callout-important}
## Exercise

Your result should look like the plot below
:::

::: {.callout-tip collapse="true"}
## Expected Result

```{r}
#| echo: false
tail(mtcars)
```
:::

## Geocomputation in R

I briefly re-iterate some of the basic principles of geocomputation in R, highlighting two key libraries to read raster and vector data.

### Raster data



`sf` and `terra`.








