# Phenology modelling

```{r include = FALSE}
library(geodata)
library(terra)
library(dplyr)
library(ggplot2)
library(patchwork)
library(hexbin)

# preloading data
# for fast processing
#harvard_phenocam_phenology <- readRDS("")

# read DAYMET gridded data
ma_nh_temp <- terra::rast("../data/daymet_mean_temperature.tif")

# read harvard forest GCC time series and matching
# DAYMET data
harvard_phenocam_data <- read.table(
  "../data-raw/harvard_DB_1000_3day.csv",
  sep = ",",
  header = TRUE,
  skip = 3
  )

# read derived phenology metrics
harvard_phenology <- read.table(
  "../data-raw/harvard_DB_1000_3day_transition_dates.csv",
  sep = ",",
  header = TRUE
) |>
  filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )
```

## Introduction

In the previous chapters (@sec-phenology-trends, @sec-algorithms) you have seen how the development of vegetation throughout the season, or phenology, is determined by temperature, and therefore through the lapse rate to topography. Although these chapters give you an intuition on how phenology might change under global heating, it does not provide a (pseudo) mechanistic model for predicting phenology.

Luckily the science around phenology is old. People been observing vegetation phenology for hundreds of years with observations of cherry blossoms in Kyoto going back to the 9th century [@aono_phenological_2008]. Furthermore, there is a good understanding of how phenology is triggered in spring and how this can be captured using (mechanistic) models. The most basic principle uses the concept of growing degree days (GDD) and first mentions go back to the 18th century as described by @DeReaumur1735. 

This growing degree day concept stipulates that spring phenology depends on the accumulation over time of growing days, i.e. days which exceed a certain threshold temperature. If a set number of growing degree days are reached it will trigger spring phenology. 

## PhenoCam validation data

To illustrate the use of growing degree days in modelling spring phenology I will use PhenoCam data. The [PhenoCam network](https://phenocam.nau.edu/webcam/) [@richardson_tracking_2018; @richardson_tracking_2018-1] uses network connected cameras to collect seasonal trajectories of vegetation greenness, as characterized with green chromatic coordinate (GCC) values. PhenoCam data can be downloaded using the [`phenocamr` R package](https://bluegreen-labs.github.io/phenocamr/) [@hufkens_integrated_2018].

The `phenocamr` R package uses the PhenoCam API to access the latest GCC time series and derive phenology using a threshold based methodology similar to that described in @sec-algorithms. The data in @fig-phenocam-harvard should therefore be familiar. The `phenocamr` API call also downloads [DAYMET data](https://daymet.ornl.gov/), which includes both daily minimum and maximum data. This ancillary data will be used in this basic modelling example below.

```{r message = FALSE, eval = FALSE}
# I will use the phenocamr package which 
# interfaces with the phenocam network API
# to download time series of vegetation 
# greenness and derived phenology metrics
library(phenocamr)

# download greenness time series,
# calculate phenology (phenophases),
# amend with DAYMET data
phenocamr::download_phenocam(
  site = "harvard$",
  veg_type = "DB",
  roi_id = "1000",
  daymet = TRUE,
  phenophase = TRUE,
  trim = 2022,
  out_dir = tempdir()
  )

harvard_phenocam_data <- read.table(
  file.path(tempdir(), "harvard_DB_1000_3day.csv"), 
  sep = ",",
  header = TRUE,
  skip = 3
  )

# reading in harvard phenology only retaining
# spring (rising) phenology for the GCC 90th
# percentile time series (the default)
harvard_phenology <- read.table(
  file.path(
    tempdir(),
    "harvard_DB_1000_3day_transition_dates.csv"
    ),
  sep = ",",
  header = TRUE
) |>
  filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )
```

```{r}
#| code-fold: true
#| label: fig-phenocam-harvard
#| fig-cap: "A time series of the 90th percentile 3-daily green chromatic coordinate (GCC) values for the Harvard forest EMS tower PhenoCam as a dark grey line, with threshold based (25% seasonal amplitude) derived phenology marked as black dots."
#| fig-align: "center"
#| out-width: "100%"
#| fig-width: 6
#| fig-height: 3

ggplot(harvard_phenocam_data) +
  geom_line(
    aes(
      as.Date(date),
      smooth_gcc_90
    ),
    colour = "grey25"
  ) +
  geom_point(
    data = harvard_phenology,
    aes(
      as.Date(transition_25),
      threshold_25
    )
  ) +
  labs(
    x = "",
    y = "GCC"
  ) +
  theme_bw() +
  theme(
    legend.position = "none"
  )

```

Growing degree days are at it's most basic specified as the cumulative sum of the days above a certain (preset) temperature. Here a growing degree day x for a temperature threshold (t) is defined as:

$x = \left\{ \begin{array}{cl} 1 & : \ x \geq t \\ 0 & : \ x < t \end{array} \right.$

$GDD_k=\sum_{i=1}^k x_i$. 

Where k is the number of growing degree days for a daily time step i. In `R` this equation is simplified to `cumsum(temperature >= 5)` with temperature a vector of temperature values and threshold of 5 $^\circ$C. Using this knowledge we can quickly calculate and plot all days which adhere to this criteria and their cumulative sum @fig-gdd.

```{r}
# return mean daily temperature as well
# as formal dates (for plotting)
harvard_temp <- harvard_phenocam_data |>
  group_by(year) |>
  dplyr::mutate(
    date = as.Date(date),
    tmean = (tmax..deg.c. + tmin..deg.c.)/2,
    gdd = cumsum(tmean >= 5)
  ) |>
  dplyr::select(
    date,
    year,
    tmean,
    gdd
  )

# convert the harvard phenology data
harvard_phenology <- harvard_phenology |>
  mutate(
    doy = format(as.Date(transition_25),"%j"),
    year = format(as.Date(transition_25),"%Y")
  )

```

```{r warning=FALSE}
#| code-fold: true
#| label: fig-gdd
#| fig-cap: "Example of the growing degree day (GDD) concept, showing both a temperature time series with days with a mean temperature below 5C in blue, those above as red (a), and the growing degree days (GDD) as the cummulative sum of warm (red) days in the bottom panel (b). The observed spring phenology (leaf out) is marked with a vertical black line."
#| fig-align: "center"
#| out-width: "100%"
#| fig-width: 6
#| fig-height: 5

p <- ggplot(harvard_temp) +
  geom_line(
    aes(
      date,
      tmean
    )
  ) +
  geom_point(
    aes(
      date,
      tmean,
      colour = tmean > 5,
      group = 1
    )
  ) +
  scale_colour_discrete(
    type = c(
      "blue",
      "red"
      )
  ) +
  labs(
    x = "",
    y = "temperature"
  ) +
  xlim(
    c(
    as.Date("2010-01-01"),
    as.Date("2010-06-30")
    )
  ) +
  theme_bw() +
  theme(
    legend.position = "none"
  )

p2 <- ggplot(harvard_temp) +
  geom_line(
    aes(
      date,
      gdd
    )
  ) +
  geom_point(
    aes(
      date,
      gdd,
      colour = tmean > 5,
      group = 1
    )
  ) +
  scale_colour_discrete(
    type = c(
      "blue",
      "red"
      )
  ) +
  labs(
    x = "",
    y = "GDD (#)"
  ) +
  xlim(
    c(
    as.Date("2010-01-01"),
    as.Date("2010-06-30")
    )
  ) +
  ylim(c(0, 120)) +
  theme_bw()  +
  theme(
    legend.position = "none"
  )

# compositing
p + p2 + 
  plot_layout(ncol = 1) + 
  plot_annotation(
    tag_levels = "a",
    tag_prefix = "(",
    tag_suffix = ")"
    )

```





More advanced models exist, which include not only temperature but also radiation, precipitation and or temporal lags or other requirements such as frost during the preceding winter depending on the vegetation type or assumptions made (REFERENCES). In this chapter I will demonstrate the concept using the most basic growing degree day model and I refer to @basler_evaluating_2016 and @hufkens_integrated_2018 for an overview of models and their implementation.

## Growing degree day model optimization

Using the concept of growing degree days I will explain how to formulate such a simple phenology model and how to optimize the parameter such model 

We can translate this growing degree day model to a mathematical formulation.

> Show figure of days to sum and over which period (starting period). There is no stop at the beginning, only defined by the in-situ observation or MCD12Q2 data. Just plot. Then move on to specifying the full model. Demonstrate which parameters lead to a singular result. Then scale, what if we have 10 observations? How to pick the best parameters.

### Phenology model optimization

When we want to estimate a general set of parameters for our growing degree day function we need to optimize them across a wide range of observations. In particular, we want to miinimize the error between the model results (for a given set of parameters) and our observed data. If you've taking any introduction to statistical or machine learning this problem will sound fairly familiar. For example, in a linear model one optimizes two parameters an intercept and a slope to minimize the difference between observed and modelled (linear) model results. In our example, we do not have a linear model but a more complex one with three parameters - however the same concept applies. 

Estimating these parameters efficiently can be done using various parameter optimization methods. Examples of such methods include simulated annealing (using the GenSA package REFERENCE), bayesian optimization methods such as BayesianTools. For simplicity I'll use the GenSA package and simulated annealing method to illustrate the estimation of model parameters.

## Spatial scaling

With a basic parameterized model you can explore how well it scales across a wider area. Here I will use DAYMET tiled data to scale the results spatially (relying on the same driver data as used during parameterization). First I download both minimum and maximum temperature data and average them to a mean daily value (as previously used).

```{r eval = FALSE}
# Download daily data
daymetr::download_daymet_tiles(
  tiles = 11935,
  start = 2012,
  end = 2012,
  param = c("tmin","tmax"),
  path = "data-raw/",
  silent = TRUE
  )

# calculate the daily mean values
r <- daymetr::daymet_grid_tmean(
  path = "data-raw",
  product = 11935,
  year = 2012,
  internal = TRUE
)
```

For convenience I reproject the data to geographic coordinates, and limit the data to the first 180 days (layers) of the dataset to reduce the memory footprint of the calculations.

```{r eval = FALSE}
# reproject to lat lon
r <- terra::project(
  r,
  "+init=epsg:4326"
)

# subset to first 180 days
ma_nh_temp <- terra::subset(
  r,
  1:180
)
```

One can then apply the model to this raster (cube) using the the `terra::app()` function and an appropriately formulated function. I refer to the `terra::app()` for the specifics on how to ensure your functions are compatible with raster processing (GENERAL RULES).

```{r eval = FALSE}
predicted_phenology <- terra::app(
  ma_nh_temp,
  fun = gdd_model(),
  par = par
)
```

```{r eval = FALSE}
#| code-fold: true

library(leaflet)

# set te colour scale manually
pal <- colorNumeric(
  "magma",
  values(predicted_phenology),
  na.color = "transparent"
  )

# build the leaflet map
# using ESRI tile servers
# and the loaded demo raster
leaflet() |> 
  addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") |>
  addProviderTiles(providers$Esri.WorldTopoMap, group = "World Topo") |>
  addRasterImage(
    predicted_phenology,
    colors = pal,
    opacity = 0.8,
    group = "Phenology model results"
    ) |>
  addLayersControl(
    baseGroups = c("World Imagery","World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE)
    ) |>
  addLegend(
    pal = pal,
    values = values(predicted_phenology),
    title = "DOY")
```

### Scaling model results

### Statistical downscaling of course data

## Remote sensing comparison
